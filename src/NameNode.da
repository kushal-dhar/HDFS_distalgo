import threading, time
from FileAttributes import Inode, Lease
from Block import BlockInfo
import Config
import random
import Utils


"""
LeaseMonitor process to monitor Lease Timeout
"""
class LeaseMonitor(process):
    def setup(namenode):
        self.hard_limit = Config.CLIENT_HARD_LIMIT   #300 seconds for hard_limit of each lease
        self.namenode = namenode

    def run():
        output("Lease Monitor process started")
        send(('getLeaseInfo', self), to=namenode)
        await(received(('kill')))


    def receive(msg=('leaseInfo', clientTimeStamp, file2leaseobj)):
        output("Received leaseinfo from NameNode")
        currentTime = time.time()
        for eachFile in file2leaseobj:
            output("lease: ",file2leaseobj[eachFile], clientTimeStamp)
            #If the writing/reading process does not send a hard limit within the hard_limit, end it
            if currentTime - clientTimeStamp[file2leaseobj[eachFile].client] >= hard_limit:
                output("file2leaseobj: ",file2leaseobj)
                send(('closeFile', Config.W_LEASE, None, file2leaseobj[eachFile].filename, -1), to=namenode)
        time.sleep(60)
        send(('getLeaseInfo', self), to=namenode)

"""
DatanodeMonitor process to monitor datanode health using heartbeats
"""
class DatanodeMonitor(process):
    def setup(namenode):
        self.timeoutLimit = Config.DATANODE_HEARTBEAT_TIMEOUT   #600 seconds
        self.checkInterval = Config.DATANODE_HEARTBEAT_CHECK_INTERVAL

    def run():
        output("Datanode Monitor process started")
        #send(('getLeaseInfo', self), to=namenode)
        while(True):
            #time.sleep(self.checkInterval)
            if await(received(('kill'))):
                output("DatanodeMonitor: received kill")
                exit(0)
            elif timeout(self.checkInterval):
                pass
            send(('provideDatanodeHeartbeatInfo'), to=namenode)



    def receive(msg=('datanodeHeartbeatInfo', datanodeHeartbeatTime, datanodeId2pid)):
        #output("DatanodeMonitor: Received datanodeHeartbeatInfo from NameNode")
        currentTime = time.time()
        dead_datanodes = []
        for datanodeId in datanodeId2pid:
            # If a datanode never sent heartbeat, assume it is not running
            if datanodeId not in datanodeHeartbeatTime:
                dead_datanodes.append(datanodeId)
            if currentTime - datanodeHeartbeatTime[datanodeId] >= self.timeoutLimit:
                dead_datanodes.append(datanodeId)
        if len(dead_datanodes) == 0:
            return
        output("datanodeHeartbeatInfo: found dead datanodes: ", dead_datanodes)
        dead_datanodes = tuple(dead_datanodes)
        send(('datanodesDead', dead_datanodes), to=namenode)



"""
Namenode process in HDFS cluster
The   NameNode   maintains   the namespace  tree  and  
the  mapping  of  file  blocks  to  DataNodes 
"""
class NameNode(process):
#class NameNode():
    """
    def __init__():
        datanodes = None
        # dict: filename -> Inode
        inodes = None
        # dict: filename -> BlockInfo
        blockinfo = None
        pass
    """
    def setup():
        self.datanodeId2pid = dict() #Mapping of datanode to pid
        self.pid2datanodeId = dict() #Reverse mapping pid to datanode
        self.nextDatanodeId = 1
        self.file2leasereq = dict() #Write request queue for a file
        self.file2leaseobj = dict() #Leaseobject mapping with file
        # dict: filename -> Inode
        self.inodes = dict() #Inodes to filename mappng
        self.clientTimeStamp = dict() #Timestamp of the heartbeats of the client

        # dict: filename -> BlockInfo
        self.blockinfo = dict() #BlockInfo objects per file.

        self.mapLock = threading.Lock()
        self.counterLock = threading.Lock()
        self.locks = [self.mapLock, self.counterLock]
        self.datanodeHeartbeatTime = dict()


    def run():
        output('namenode running: ', self)
        monitorProcess = new(LeaseMonitor, num=1, at=Config.NAMENODE_LOCATION)
        for mp in monitorProcess:
            setup(mp, args=(self,))
        start(monitorProcess)

        datanodeMonitorProcess = new(DatanodeMonitor, num=1, at=Config.NAMENODE_LOCATION)
        for dp in datanodeMonitorProcess:
            setup(dp, args=(self,))
        start(datanodeMonitorProcess)

        await(received(('kill')))


    def nominateDataNodes(filename, count=3):
        """
        Nominates `count` datanodes for storing a new block of a file
        """
        pass


    def getDatanodesOfBlock(filename, blockNumber):
        """
        Returns the datanodes at which the block `blockNumber` of `filename` is located
        """
        pass


    def getImage():
        """
        Returns the current image of namesystem.
        It containes blockinfo and inode data.
        """
        pass


    def connectDatanode(datanode):
        """
        Performs handshake and verification of datanode.
        After this passes, datanode is available for storing data blocks.
        """
        pass


    def handleBlockReport(datanode, report):
        """
        Analyses the block report sent by datanode.
        Done asynchronously.
        """
        pass


    def handleDatanodeHeartbeat(datanode, heatbeat):
        """
        Analyse the heartbeat message sent by datanode.
        Replies to the heartbeat and sends further instructions.
        """
        pass


    def handleDatanodeDown(datanode):
        """
        Takes the necessary steps when a datanode is presumed to be down.
        Schedules replciation of the blocks which the datanode was storing.
        """
        pass


    def analyseSystemHealth():
        """
        Perform analysis of overall health of the system.
        - schedule replication of under replicated blocks
        - schedule deletion of over replicated blocks
        - take action when storage on datanode is running out
        - do garbage collection
        """
        pass

    """The  HDFS  client  that  opens  a  file  for  writing  is  granted  a 
       lease for the file; no other client can write to the file. The writ-
       ing  client  periodically  renews  the  lease  by  sending  a  heartbeat 
       to the NameNode
       For writers we are just increasing the read count.
    """
    def grantLease(client, req_info):
        """
        Grants lease of `filename` to the client.
        """
        if(req_info[0] not in self.file2leaseobj):
             leaseObj = Lease(client, req_info[0],req_info[1])
             if req_info[1] == Config.R_LEASE:
                 leaseObj.readers += 1
             self.file2leaseobj[req_info[0]] =  leaseObj
        else:
            leaseObj = self.file2leaseobj[req_info[0]]
            # If mode is READERS, increase READERS count otherwise make leaseType as WRITE_LEASE
            # so that during deletion, we don't delete incase someone is reading or writing
            if req_info[1] == Config.R_LEASE:
                leaseObj.readers += 1
            else:
                leaseObj.leaseType = req_info[1]
            self.file2leaseobj[req_info[0]] = leaseObj
        output("Lease acquired for file: %s by client: %s" %(req_info[0], client))
        send(('openFile', req_info[0], req_info[1], req_info[2], True), to=client)

    """
        
    """
    def handleCorruptedBlock(filename, blockNumber):
        """
        Performs the necessary actions when it is notified that a block has been corrupted
        """
        pass


    def receive(msg=('hello')):
        output('handler: received hello from someone')

    """
       DataNode registers with the NameNode
    """
    def receive(msg=('add_datanode', datanode, proposedId)):
        output('received add_datanode: ', datanode)
        if proposedId is None:
            acquireLock(counterLock)
            pid2datanodeId[datanode] = self.nextDatanodeId
            datanodeId2pid[self.nextDatanodeId] = datanode
            self.nextDatanodeId += 1
            releaseLock(counterLock)
        elif proposedId not in datanodeId2pid:
            acquireLock(mapLock)
            pid2datanodeId[datanode] = proposedId
            datanodeId2pid[proposedId] = datanode
            releaseLock(mapLock)
        else:
            oldPid = datanodeId2pid[proposedId]
            acquireLock(mapLock)
            pid2datanodeId.pop(oldPid, None)
            pid2datanodeId[datanode] = proposedId
            datanodeId2pid[proposedId] = datanode
            releaseLock(mapLock)
        send(('datanode_added', pid2datanodeId[datanode]), to=set([datanode]))
        output('added datanode: ', datanode, ' -> ', pid2datanodeId[datanode])



    def receive(msg=('heartbeat_datanode', datanode)):
        # datanode is pid of sending datanode
        #output('received heartbeat from datanode: ', datanode)
        currentTime = time.time()
        # If datanode registered with namenode, this lookup will never fail :)
        datanodeId = self.pid2datanodeId[datanode]
        self.datanodeHeartbeatTime[datanodeId] = currentTime



    def receive(msg=('heartbeat_client',clientnode)):
        #output('received hearbeat from clientnode: ', clientnode)
        clientTimeStamp[clientnode] = time.time()

    """
    Define the metadata for the newly created file
    """
    def receive(msg=('createFile', client, filename, messageId)):
        output('received create file ', filename, ' request from ', client)
        if filename in self.inodes:
            send(('createFile', filename, messageId, True), to=client)
            return
        self.inodes[filename] = Inode(filename)
        self.blockinfo[filename] = BlockInfo(filename, self.inodes[filename])
        #output('sending to client: ', ('createFile', filename, messageId, True))
        send(('createFile', filename, messageId, True), to=client)

    """
    Serve the map of the files present in the Namenode
    """
    def receive(msg=('listFiles', client, messageId)):
        output('received listFiles request from : ', client)
        files = tuple([filename for filename in inodes])

        output('list of files: ', files)
        send(('listFiles', messageId, files), to=client)


    """
        The  HDFS  client  that  opens  a  file  for  writing  is  granted  a 
        lease for the file
    """
    def receive(msg=('openFile', mode, client, filename, messageId)):
        output('received openFile request from : ', client)
        #Return false if the file does not exist
        if filename not in self.inodes:
            output('file ', filename, ' not present')
            result = False
        else:
            req_info = (filename, mode, messageId, client)
            #Multiple readers can work on the file at the same time.
            if(mode  == Config.R_LEASE):
                grantLease(client, req_info)
            else:
                if(filename in self.file2leasereq and len(file2leasereq[filename]) > 0):
                   self.file2leasereq[filename].append(req_info)
                   return
                else:
                    #First request, we can grant it access and generate lease obj
                    self.file2leasereq[filename] = []
                    self.file2leasereq[filename].append(req_info)
                    grantLease(client, req_info)
            # acquire lease for the file
            output('acquired lease for filename: ', filename)
            result = True
        send(('openFile', filename, mode, messageId, result), to=client)
        output("Message sent from Namenode to client")

    """
        An HDFS client wanting to 
        read a file first contacts the NameNode for the locations of data 
        blocks  comprising  the  file 
    """
    def receive(msg=('readFile_c2n', client, filename, blockNumber, nbytes, messageId)):
        output('received readFile request from {0}: filename={1}, blockNumber={2}, nbytes={3}'.format(client, filename, blockNumber, nbytes))

        datanodes_hosting_ids = self.blockinfo[filename].getDatanodeIdsForBlock(blockNumber)
        running_datanodes_hosting_Pids = []
        # Return only pid of running datanodes
        for d in datanodes_hosting_ids:
            if d in self.datanodeId2pid:
                running_datanodes_hosting_Pids.append(self.datanodeId2pid[d])
        running_datanodes_hosting_Pids = tuple(running_datanodes_hosting_Pids)
        filepath = filename + '.block.' + str(blockNumber)

        result = (filepath, running_datanodes_hosting_Pids)
        output('namenode: result of readfile: ', result)
        send(('readFile_n2c', filename, blockNumber, messageId, result), to=client)

    """
         When the file is closed, the lease is revoked
    """
    def receive(msg=('closeFile', mode, client, filename, messageId)):
        output('received closeFile request from : ', client)
        output('releasing lease for file: ',filename)
        if (mode == Config.R_LEASE):
            # Decrease the number of readers count for this file
            leaseObj = file2leaseobj[filename]
            leaseObj.readers -= 1
            file2leaseobj[filename] = leaseObj
            send(('closeFile', filename, mode, messageId, True), to=client)
        else:
            self.file2leasereq[filename].pop(0)
            if len(file2leasereq[filename]) > 0:
                req_info =  self.file2leasereq[filename][0]
                send(('closeFile', filename, mode, messageId, True), to=client)
                grantLease(req_info[3],req_info)
                output("Closed File: ",filename)
            else:
                leaseObj = file2leaseobj[filename]
                leaseObj.leaseType = None
                self.file2leaseobj[filename] = leaseObj
                send(('closeFile', filename, mode, messageId, True), to=client)
                output("Closed File: ",filename)
            """
            TO-DO : Add the timestamp for latest lease
            """
    """
        Check if there are readers on this file or if a lease is taken.If not delete is suvvessful
    """
    def receive(msg=('deleteFile', client, filename, messageId)):
        output('received deleteFile request from: %s for file: %s' %(client, filename))
        leaseObj = file2leaseobj[filename]
        # If there are no reader and writer process working on this file, then delete this file
        if leaseObj.leaseType == None and leaseObj.readers == 0:
            output("deleteFile: Going to delete file: ",filename)
            numBlocks = blockinfo[filename].getNumberOfBlocks()
            for block in range(numBlocks):
                dataNodes = blockinfo[filename].getDatanodeIdsForBlock(block)
                blockname = filename + '.block.' + str(block)
                for node in dataNodes:
                    dataNodePID = datanodeId2pid[node]
                    send(('deleteBlock', blockname), to=dataNodePID)
            del blockinfo[filename]
            del inodes[filename]

            send(('deleteFile', filename, messageId, True), to=client)
        else:
            send(('deleteFile', filename, messageId, False), to=client)


    def receive(msg=('getLeaseInfo', leaseMonitor)):
        output('received getLeaseInfo from LeaseMonitor')
        send(('leaseInfo', clientTimeStamp, file2leaseobj), to=leaseMonitor)

    """
        When  writing  data,  the  cli-
        ent  requests  the  NameNode  to  nominate  a  suite  of  three 
        DataNodes  to  host  the  block  replica        
    """
    def receive(msg=('appendFile_c2n', client, filename, messageId)):
        output('received appendFile request from {0}: filename={1}, messageId={2}'.format(client, filename, messageId))

        blockNumber, bytesToWrite, newDatanodeToWrite = self.blockinfo[filename].getNewAppendInfo()

        # Create fresh block and store data
        if newDatanodeToWrite:
            #output("namenode: allocating new block for append to filename={0}".format(filename))
            datanodes = [d for d in self.pid2datanodeId.keys()]
            # If alive datanodes are less than replication factor, nominate all datanodes for storing blocks
            if len(datanodes) > Config.BLOCK_REPLICATION_FACTOR:
                selectedDatanodes = tuple(random.sample(datanodes, Config.BLOCK_REPLICATION_FACTOR))
            else:
                selectedDatanodes = tuple(datanodes)
            #bytesToWrite = Config.BLOCK_SIZE
            #blockNumber = self.blockinfo[filename].getLastBlockNumber() + 1
        # Append to the last written block
        else:
            #bytesToWrite = Config.BLOCK_SIZE - lastBlockSize
            #output("namenode: appending to last block for append to filename={0}".format(filename))
            selectedDatanodeIds = self.blockinfo[filename].getLastBlockDatanodeIds()
            # Get PID from datanode Id
            # TODO - handle datanode failure - done
            selectedDatanodes = []
            # Find datanodes which are running
            for d in selectedDatanodeIds:
                if d in self.datanodeId2pid:
                    selectedDatanodes.append(self.datanodeId2pid[d])
            selectedDatanodes = tuple(selectedDatanodes)
            #blockNumber = self.blockinfo[filename].getLastBlockNumber()

        blockName = filename + '.block.' + str(blockNumber)
        replyData = (selectedDatanodes, blockName, bytesToWrite, blockNumber)
        send(('appendFile_n2c', filename, messageId, replyData), to=client)


    def receive(msg=('appendFile_d2n', filename, blockNumber, bytesWritten, datanodeId)):
        #output("namenode: received appendFile confirmation for filename={0} from datanode={1}".format(filename, datanodeId))
        # update this append information in blockinfo
        self.blockinfo[filename].addAppendInfo(blockNumber, bytesWritten, datanodeId)
        #output("namenode: after append info={0}".format(str(self.blockinfo[filename])))


    def receive(msg=('numBlocksInFile', filename, messageId), from_= client):
        nBlocks = self.blockinfo[filename].getNumberOfBlocks()
        send(('numBlocksInFile', filename, messageId, nBlocks), to=client)

    def receive(msg=('provideDatanodeHeartbeatInfo'), from_=datanodeHeartbeatMonitorProcess):
        #output("namenode: received provideDatanodeHeartbeatInfo")
        send(('datanodeHeartbeatInfo', self.datanodeHeartbeatTime, self.datanodeId2pid), to=datanodeHeartbeatMonitorProcess)

    """
        If  the  number  of  existing  replicas  is  one,  HDFS namenode 
        places the next replica on a different namenode
    """
    def receive(msg=('datanodesDead', dead_datanodes)):
        output("namenode: detected datanode failure at datanodeIds={0}".format(dead_datanodes))
        #remove it from th datanode to id map
        for dn in dead_datanodes:
            pid = self.datanodeId2pid[dn]
            acquireLock(mapLock)
            self.datanodeId2pid.pop(dn, None)
            self.pid2datanodeId.pop(pid)
            releaseLock(mapLock)


        dead_datanodes = set(dead_datanodes)
        alive_datanodes = set(dn for dn in self.datanodeId2pid.keys())
        output("namenode: identified alive datanodes: ", alive_datanodes)
        for filename in self.blockinfo.keys():
            nblocks = self.blockinfo[filename].getNumberOfBlocks()
            for blockNumber in range(nblocks):
                storing_datanodes = set(self.blockinfo[filename].getDatanodeIdsForBlock(blockNumber))
                storing_datanodes_dead = storing_datanodes.intersection(dead_datanodes)
                storing_datanodes_live = storing_datanodes.difference(storing_datanodes_dead)
                output("namenode: storing={0}, dead={1}, live={2}".format(storing_datanodes, storing_datanodes_dead, storing_datanodes_live))
                if len(storing_datanodes_live) >= Config.BLOCK_REPLICATION_FACTOR:
                    output("block already replicated more than replicator_factor times")
                    continue
                if len(storing_datanodes_live) == 0:
                    output("all datanodes for storing block={0} for file={1} are dead!!!".format(blockNumber, filename))
                    continue
                candidate_datanodes = alive_datanodes.difference(storing_datanodes_live)
                if len(candidate_datanodes) == 0:
                    output("all live datanodes already stroe block={0} for file={1}".format(blockNumber, filename))
                    continue
                #If replication factor is 1 then we send the block to a datanode to write it on a destination datanode.
                destination_datanode = random.sample(candidate_datanodes, 1)
                destination_datanode = self.datanodeId2pid[destination_datanode[0]]
                source_datanode = random.sample(storing_datanodes_live, 1)
                source_datanode = self.datanodeId2pid[source_datanode[0]]
                blockFileName = filename + '.block.' + str(blockNumber)
                output("namenode: replicating from={0}, to={1}".format(source_datanode, destination_datanode))
                output("storing block={0} for file={1} from={2} to={3}".format(blockNumber, filename, source_datanode, destination_datanode))
                send(('replicateBlock_n2d', filename, blockNumber, blockFileName, destination_datanode), to=source_datanode)



    def acquireLock(lockObj):
        for obj in locks:
            if obj != lockObj:
                obj.acquire()
            else:
                obj.acquire()
                break
        return


    def releaseLock(lockObj):
        lockFound = False
        for obj in reversed(locks):
            if obj != lockObj and not lockFound:
                continue
            if obj == lockObj:
                obj.release()
                lockFound = True
            elif lockFound:
                obj.release()
        return

